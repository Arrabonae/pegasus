Below is a sample README.md that you could use for this project. It covers the project background, technology stack, and installation instructions for both the UI (Next.js + Tailwind) and server (FastAPI/Python). Feel free to tailor it further to match your specific requirements or preferences.

Pegasus

Pegasus is an AI-driven financial analysis platform designed to streamline document ingestion and reporting. It uses large language models (LLMs) for both text and multimodal (vision) tasks, enabling complex PDF ingestion, chunk-wise summaries, and robust interactive chat features.

Table of Contents
	•	Background
	•	Features
	•	Tech Stack
	•	Project Structure
	•	Installation
	•	Prerequisites
	•	Server Setup (Python)
	•	UI Setup (Next.js)
	•	Running the Application
	•	Usage
	•	License

Background

Financial analysts frequently work with large, unstructured documents (PDFs, Word documents, etc.) and spend significant time extracting key metrics and commentary to produce financial reports. Pegasus automates and augments this process by:
	1.	Indexing documents (supporting PDF, DOC, DOCX) for quick retrieval.
	2.	Generating chunk-based summaries for complex multi-page files (using a vision-language model).
	3.	Creating a comprehensive financial analysis report with minimal user input.
	4.	Offering a user-friendly chat interface to query the ingested documents.

Features
	•	Document Ingestion & Indexing
Upload PDF/DOC/DOCX documents, automatically convert them to text or PDF, and index them for retrieval.
	•	RAG (Retrieval-Augmented Generation with colpali)
Use Byaldi’s RAGMultiModalModel to fetch relevant pages or sections from ingested PDFs.
	•	Vision + Text Models
Summaries are generated by a large vision-language model (Qwen2-VL) for PDFs, while text-only LLMs (Qwen2.5-XB) create the final comprehensive report.
	•	Interactive Chat
Pose financial or general questions; the system automatically retrieves supporting context from indexed documents.
	•	Report Generation
Generate a cohesive multi-section analysis, including an executive summary, key metrics (table), detailed analysis, trends/patterns, and final recommendations.

Tech Stack

Server
	•	Language & Framework: Python 3.11, FastAPI
	•	Core Libraries:
	•	Byaldi for RAG indexing
	•	Transformers for model loading
	•	docx2pdf for document conversion
	•	PyMuPDF (fitz) for PDF processing

UI
	•	Language & Framework: TypeScript, Next.js 15 (App Router)
	•	Styling: Tailwind CSS
	•	UI Components: Radix UI, ShadCN/UI libraries
	•	State Management: React hooks & local state
	•	Other Libraries:
	•	React Dropzone for file uploads
	•	React Markdown and showdown for Markdown rendering
	•	Plotly.js / Chart.js (for future charts/graphs)

Project Structure

Below is a brief overview of the folder structure:

pegasus/
├── server/                        # Python/fastAPI server code
│   ├── config.py                 # General server configs
│   ├── converters.py             # Doc -> PDF conversion
│   ├── indexer.py                # Document indexing logic
│   ├── logger.py                 # Logging configuration
│   ├── main.py                   # FastAPI entry point
│   ├── model_loader.py           # Loading text or VLM models
│   ├── responder.py              # Chat and report generation routines
│   └── retriever.py              # Retrieve relevant docs
├── src/                          # Next.js/React client code (UI)
│   ├── app/                      # Next.js app directory
│   ├── components/               # Reusable UI components
│   ├── hooks/                    # Custom React hooks
│   └── lib/                      # Utility functions
├── static/                       # Static files for server
├── package.json                  # Node.js dependencies
├── pyproject.toml                # Python dependencies & project metadata
├── requirements.txt              # (optional) Traditional python deps file
├── tailwind.config.ts            # Tailwind config
├── postcss.config.mjs            # PostCSS config
├── next.config.mjs               # Next.js config in ESM
├── next.config.js                # Next.js config in CJS (example)
└── README.md                     # Project README (this file)

Installation

Prerequisites
	1.	Python 3.11 (ensure you have at least Python 3.8+, this project specifically uses 3.11)
	2.	Node.js & npm (latest LTS recommended, e.g., Node 18+)
	3.	Git (to clone the repository)

Server Setup (Python)
	1.	Clone the Repository (or download the project folder).

git clone https://github.com/your-username/pegasus.git
cd pegasus


	2.	Create & Activate a Virtual Environment (optional but recommended).

python3.11 -m venv venv
source venv/bin/activate   # Mac/Linux
# or on Windows:
# venv\Scripts\activate


	3.	Install Python Dependencies.

# Option 1: Using pyproject.toml (preferred if you have poetry, etc.)
pip install --upgrade pip
pip install .

# or Option 2: Using requirements.txt
pip install -r requirements.txt


	4.	Run the Server.

# from within the "pegasus" folder
uvicorn server.main:app --host 0.0.0.0 --port 5050 --reload

The server should start on http://localhost:5050.

UI Setup (Next.js)
	1.	Install Node Dependencies.

# from within the same "pegasus" root folder
npm install
# or
yarn install


	2.	Configure Environment (Optional)
If you have any environment-specific variables, place them in .env.local (Next.js convention) or .env for general usage.
	3.	Run the Development Server.

npm run dev
# or
yarn dev

The UI should be available at http://localhost:3000.

Running the Application
	1.	Start the Python (FastAPI) Server on port 5050.
	2.	Start the Next.js Dev Server on port 3000.
	3.	Open a browser and navigate to http://localhost:3000.
	•	The UI will communicate with the backend at http://localhost:5050 (by default, as specified in the code).

Usage
	1.	Create a New Thread
	•	Click the “New Thread” button in the sidebar.
	•	Upload a PDF, DOC, or DOCX file, and give your thread a descriptive title.
	•	The server will index the file in the background.
	•	Once indexing is complete, you can query or generate a report.
	2.	Add Additional Files
	•	In the right sidebar’s “Files” tab, use the paperclip icon to add new files to the current session.
	3.	Chat with the AI
	•	Use the chat box at the bottom-right to ask questions.
	•	The AI will retrieve relevant pages from the indexed documents, providing answers with references.
	4.	Generate a Report
	•	In the main “Report” panel, click “Generate Report.”
	•	A final multi-section report will be created using the vision + text LLM pipeline.

License

This project is licensed under the MIT License.

Feel free to modify or extend this README as you see fit!

Happy analyzing!